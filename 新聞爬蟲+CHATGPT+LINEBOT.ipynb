{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYaLmMIv3vcMA2dQvD6zPz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skywalker0803r/NewsCrawler_CHATGPT_LINEBOT/blob/main/%E6%96%B0%E8%81%9E%E7%88%AC%E8%9F%B2%2BCHATGPT%2BLINEBOT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1vAcZM1Y-jkD"
      },
      "outputs": [],
      "source": [
        "# 載入套件\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import datetime\n",
        "\n",
        "# 整理Google新聞資料用\n",
        "def arrangeGoogleNews(elem):\n",
        "    return ([elem.find('title').getText(),\n",
        "             elem.find('link').getText(),\n",
        "             elem.find('pubDate').getText(),\n",
        "             BeautifulSoup(elem.find('description').getText(), 'html.parser').find('a').getText(),\n",
        "             elem.find('source').getText()])\n",
        "\n",
        "\n",
        "# 擷取各家新聞網站新聞函數\n",
        "def beautifulSoupNews(url):\n",
        "\n",
        "    # 設定hearers\n",
        "    headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) '\n",
        "                             'Chrome/87.0.4280.141 Safari/537.36'}\n",
        "\n",
        "    # 取得Google跳轉頁面的新聞連結\n",
        "    response = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    newsUrl = soup.find_all('c-wiz', class_='jtabgf')[0].getText()\n",
        "    newsUrl = newsUrl.replace('Opening ', '')\n",
        "\n",
        "    # 取得該篇新聞連結內容\n",
        "    response = requests.get(newsUrl, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser') \n",
        "\n",
        "    # 判斷url網域做對應文章擷取\n",
        "    domain = re.findall('https://[^/]*', newsUrl)[0].replace('https://', '')\n",
        "\n",
        "    if domain == 'udn.com':\n",
        "\n",
        "        # 聯合新聞網\n",
        "        item = soup.find_all('section', class_='article-content__editor')[0].find_all('p')\n",
        "        content = [elem.getText() for elem in item]\n",
        "        content = ''.join(content)\n",
        "        content = content.replace('\\r', ' ').replace('\\n', ' ')\n",
        "\n",
        "    elif domain == 'ec.ltn.com.tw':\n",
        "\n",
        "        # 自由財經\n",
        "        item = soup.find_all('div', class_='text')[0].find_all('p', class_='')\n",
        "        content = [elem.getText() for elem in item]\n",
        "        content = ''.join(content)\n",
        "        content = content.replace('\\r', ' ').replace('\\n', ' ').replace(u'\\xa0', ' '). \\\n",
        "            replace('一手掌握經濟脈動', '').replace('點我訂閱自由財經Youtube頻道', '')\n",
        "\n",
        "    elif domain in ['tw.stock.yahoo.com', 'tw.news.yahoo.com']:\n",
        "\n",
        "        # Yahoo奇摩股市\n",
        "        item = soup.find_all('div', class_='caas-body')[0].find_all('p')\n",
        "        content = [elem.getText() for elem in item]\n",
        "        del_text = soup.find_all('div', class_='caas-body')[0].find_all('a')\n",
        "        del_text = [elem.getText() for elem in del_text]\n",
        "        content = [elem for elem in content if elem not in del_text]\n",
        "        content = ''.join(content)\n",
        "        content = content.replace('\\r', ' ').replace('\\n', ' ').replace(u'\\xa0', ' ')\n",
        "\n",
        "    elif domain == 'money.udn.com':\n",
        "\n",
        "        # 經濟日報\n",
        "        item = soup.find_all('section', id='article_body')[0].find_all('p')\n",
        "        content = [elem.getText() for elem in item]\n",
        "        content = [elem for elem in content]\n",
        "        content = ''.join(content)\n",
        "        content = content.replace('\\r', ' ').replace('\\n', ' ')\n",
        "\n",
        "    elif domain == 'www.chinatimes.com':\n",
        "\n",
        "        # 中時新聞網\n",
        "        item = soup.find_all('div', class_='article-body')[0].find_all('p')\n",
        "        content = [elem.getText() for elem in item]\n",
        "        content = [elem for elem in content]\n",
        "        content = ''.join(content)\n",
        "        content = content.replace('\\r', ' ').replace('\\n', ' ')\n",
        "\n",
        "    elif domain == 'ctee.com.tw':\n",
        "\n",
        "        # 工商時報\n",
        "        item = soup.find_all('div', class_='entry-content clearfix single-post-content')[0].find_all('p')\n",
        "        content = [elem.getText() for elem in item]\n",
        "        content = [elem for elem in content]\n",
        "        content = ''.join(content)\n",
        "        content = content.replace('\\r', ' ').replace('\\n', ' ')\n",
        "\n",
        "    elif domain == 'news.cnyes.com':\n",
        "\n",
        "        # 鉅亨網\n",
        "        item = soup.find_all('div', itemprop='articleBody')[0].find_all('p')\n",
        "        content = [elem.getText() for elem in item]\n",
        "        content = [elem for elem in content]\n",
        "        content = ''.join(content)\n",
        "        content = content.replace('\\r', ' ').replace('\\n', ' ').replace(u'\\xa0', ' ')\n",
        "\n",
        "    elif domain == 'finance.ettoday.net':\n",
        "\n",
        "        # ETtoday\n",
        "        item = soup.find_all('div', itemprop='articleBody')[0].find_all('p')\n",
        "        content = [elem.getText() for elem in item]\n",
        "        content = [elem for elem in content]\n",
        "        content = ''.join(content)\n",
        "        content = content.replace('\\r', ' ').replace('\\n', ' ').replace(u'\\xa0', ' ')\n",
        "\n",
        "    elif domain == 'fnc.ebc.net.tw':\n",
        "\n",
        "        # EBC東森財經新聞\n",
        "        content = str(soup.find_all('script')[-2]).split('ReactDOM.render(React.createElement(')[1]\n",
        "        content = content.split(',')[1].replace('{\"content\":\"', '').replace('\"})', '')\n",
        "        content = re.sub(u'\\\\\\\\u003[a-z]+', '', content)\n",
        "        content = content.replace('/p', ' ').replace('\\\\n', '')\n",
        "\n",
        "    else:\n",
        "\n",
        "        # 未知domain\n",
        "        content = 'unknow domain'\n",
        "\n",
        "    return newsUrl, content\n",
        "\n",
        "\n",
        "# 迴圈下載股票清單的Google新聞資料\n",
        "\n",
        "def google_news_download(searchList,nearStartDate):\n",
        "  stockNews = pd.DataFrame()\n",
        "  for iSearch in range(len(searchList)):\n",
        "\n",
        "      print('目前正在搜尋股票: ' + searchList[iSearch] +\n",
        "            ' 在Google的新聞清單  進度: ' + str(iSearch + 1) + ' / ' + str(len(searchList)))\n",
        "\n",
        "      # 建立搜尋網址\n",
        "      url = 'https://news.google.com/news/rss/search/section/q/' + \\\n",
        "            searchList[iSearch] + '/?hl=zh-tw&gl=TW&ned=zh-tw_tw'\n",
        "      response = requests.get(url)\n",
        "      soup = BeautifulSoup(response.text, 'xml')\n",
        "      item = soup.find_all('item')\n",
        "      rows = [arrangeGoogleNews(elem) for elem in item]\n",
        "\n",
        "      # 組成pandas\n",
        "      df = pd.DataFrame(data=rows, columns=['title', 'link', 'pub_date', 'description', 'source'])\n",
        "      # 新增時間戳記欄位\n",
        "      df.insert(0, 'search_time', time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()), True)\n",
        "      # 新增搜尋字串\n",
        "      df.insert(1, 'search_key', searchList[iSearch], True)\n",
        "      # 篩選最近的新聞\n",
        "      df['pub_date'] = df['pub_date'].astype('datetime64[ns]')\n",
        "      df = df[df['pub_date'] >= nearStartDate]\n",
        "      # 按發布時間排序\n",
        "      df = df.sort_values(['pub_date']).reset_index(drop=True)\n",
        "\n",
        "      # 迴圈爬取新聞連結與內容\n",
        "      newsUrls = list()\n",
        "      contents = list()\n",
        "      for iLink in range(len(df['link'])):\n",
        "\n",
        "          print('目前正在下載: ' + searchList[iSearch] +\n",
        "                ' 各家新聞  進度: ' + str(iLink + 1) + ' / ' + str(len(df['link'])))\n",
        "\n",
        "          newsUrl, content = beautifulSoupNews(url=df['link'][iLink])\n",
        "          newsUrls.append(newsUrl)\n",
        "          contents.append(content)\n",
        "          time.sleep(3)\n",
        "\n",
        "      # 新增新聞連結與內容欄位\n",
        "      df['newsUrl'] = newsUrls\n",
        "      df['content'] = contents\n",
        "\n",
        "      # 儲存資料\n",
        "      stockNews = pd.concat([stockNews, df])\n",
        "\n",
        "  # 輸出結果檢查\n",
        "  stockNews.to_csv('checkData.csv', index=False, encoding='utf-8-sig')\n",
        "  return stockNews"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.呼叫爬蟲函數取得特定關鍵字和特定時間區段的新聞"
      ],
      "metadata": {
        "id": "8DTfyESybn2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 參數設定\n",
        "# 欲下載新聞的股票關鍵字清單\n",
        "searchList = ['2330']#, '2317鴻海', '2412中華電']\n",
        "# 新聞下載起始日\n",
        "nearStartDate = (datetime.date.today() + datetime.timedelta(days=-1)).strftime('%Y-%m-%d')\n",
        "df = google_news_download(searchList,nearStartDate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QYteD6pBfRE",
        "outputId": "2bd7a114-9c0e-4683-850e-6c23c3822ef2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "目前正在搜尋股票: 2330 在Google的新聞清單  進度: 1 / 1\n",
            "目前正在下載: 2330 各家新聞  進度: 1 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 2 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 3 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 4 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 5 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 6 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 7 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 8 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 9 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 10 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 11 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 12 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 13 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 14 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 15 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 16 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 17 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 18 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 19 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 20 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 21 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 22 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 23 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 24 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 25 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 26 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 27 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 28 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 29 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 30 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 31 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 32 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 33 / 34\n",
            "目前正在下載: 2330 各家新聞  進度: 34 / 34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)['content']"
      ],
      "metadata": {
        "id": "V03yrbggB6VH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b5cea3d-e527-49a3-f7a7-9b581df861a3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    【時報-台北電】受累銀行股重挫及觀望Fed決議，隔夜美股三大指數跌逾1%。台股今日在權王台積...\n",
              "1    【時報記者王逸芯台北報導】靜待本周美國Fed公布最新利率政策，又見兩家區域銀行賣壓洶湧，Pa...\n",
              "2    ▲AMD執行長蘇姿丰。（圖／AMD提供）記者高兆麟／綜合報導台積電大客戶超微(AMD)公布首...\n",
              "3    【時報-台北電】台股今日在美股下挫、台積電(2330)失守500關影響下，盤初一度大跌百餘點...\n",
              "4       台積電（2330）今天股價走勢疲弱，開盤跳空摜破500元關卡，達496元，下跌5元，市...\n",
              "5    【時報記者王逸芯台北報導】美國再爆銀行地雷，台股遭受波及，台股今(3)日開低震盪，權值股無力...\n",
              "6    半導體產業庫存修正比預期長引發各界關注下半年恐旺季不旺的情況，對此世界先進（5347）今（3...\n",
              "7    針對台積電（2330）美國設廠，是否造成先進製程與半導體產業鏈全面外移，並影響到台灣經濟？鴻...\n",
              "8    ▲施振榮及宏碁經營團隊也遭網路冒名詐騙。（圖／記者蕭文康攝）記者蕭文康／台北報導近期名人遭冒...\n",
              "9    （中央社記者張建中台北2023年5月3日電）台股今天震盪下跌83.07點，失守15600點關...\n",
              "Name: content, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.將前10則新聞拿去問CHATGPT未來漲跌機率"
      ],
      "metadata": {
        "id": "e6Y79TSiioql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "magic_word = '根據新聞判斷未來可能漲跌,盡可能簡短,用類似以下句型:XXX,根據新聞未來看X機率XX%'\n",
        "API_KEY = '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'\n",
        "response_list = []\n",
        "for news in df.head(10)['content']:\n",
        "  Q = news[:500]+magic_word\n",
        "  response = requests.post('https://api.openai.com/v1/chat/completions',\n",
        "                           headers={'Content-Type': 'application/json','Authorization': f'Bearer {API_KEY}'},\n",
        "                           json={'model': 'gpt-3.5-turbo','messages': [{\"role\": \"user\", \"content\": Q}],})\n",
        "\n",
        "  print(response.json())\n",
        "  print('===========')\n",
        "  response_list.append(response.json())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8s5pWMqgC3Y",
        "outputId": "bb37f875-155c-4eb1-b7a7-073cc4e0872a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'insufficient_quota', 'param': None, 'code': None}}\n",
            "===========\n",
            "{'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'insufficient_quota', 'param': None, 'code': None}}\n",
            "===========\n",
            "{'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'insufficient_quota', 'param': None, 'code': None}}\n",
            "===========\n",
            "{'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'insufficient_quota', 'param': None, 'code': None}}\n",
            "===========\n",
            "{'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'insufficient_quota', 'param': None, 'code': None}}\n",
            "===========\n",
            "{'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'insufficient_quota', 'param': None, 'code': None}}\n",
            "===========\n",
            "{'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'insufficient_quota', 'param': None, 'code': None}}\n",
            "===========\n",
            "{'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'insufficient_quota', 'param': None, 'code': None}}\n",
            "===========\n",
            "{'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'insufficient_quota', 'param': None, 'code': None}}\n",
            "===========\n",
            "{'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'insufficient_quota', 'param': None, 'code': None}}\n",
            "===========\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.將10則總結發送至LINE BOT"
      ],
      "metadata": {
        "id": "MT_3lfiwi36_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token = '5kICaBiVxMwVBoP2EB4ZomImaet1xvwiXMrKHER3SDJUVOaeuPZyrHGWXXXCIrF9JkjBynrWTRh93wYcjTNwCUS6FgUWSTSvwryyzfQx7q/uxct6LlHs5gs1QjcNwfUm6NqcmTLh923ezTaa3GLRAQdB04t89/1O/w1cDnyilFU='\n",
        "id = 'Uc13726ca34cc65314694bad1cb6b7394'\n",
        "from linebot import LineBotApi\n",
        "from linebot.models import TextSendMessage\n",
        "line_bot_api = LineBotApi(token)\n",
        "for r in response_list:\n",
        "  message = TextSendMessage(text=str(r))\n",
        "  line_bot_api.push_message(id, message)"
      ],
      "metadata": {
        "id": "2ztG5O4Vi4Un"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B4HLkF2cjTnk"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}